{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3251,
     "status": "ok",
     "timestamp": 1607029109944,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "2f5Q7408PGCM"
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import os\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def download_landmarks(dst_file):\n",
    "    url = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\n",
    "    decompressor = bz2.BZ2Decompressor()\n",
    "    \n",
    "    with urlopen(url) as src, open(dst_file, 'wb') as dst:\n",
    "        data = src.read(1024)\n",
    "        while len(data) > 0:\n",
    "            dst.write(decompressor.decompress(data))\n",
    "            data = src.read(1024)\n",
    "\n",
    "dst_dir = 'models'\n",
    "dst_file = os.path.join(dst_dir, 'landmarks.dat')\n",
    "\n",
    "if not os.path.exists(dst_file):\n",
    "    os.makedirs(dst_dir)\n",
    "    download_landmarks(dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5794,
     "status": "ok",
     "timestamp": 1607029112491,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "m7PM60fMQN8n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import create_model\n",
    "nn4_small2=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7885,
     "status": "ok",
     "timestamp": 1607029114587,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "j5LV3MYVOce7"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Layer\n",
    "\n",
    "# Input for anchor, positive and negative images\n",
    "in_a = Input(shape=(96, 96, 3))\n",
    "in_p = Input(shape=(96, 96, 3))\n",
    "in_n = Input(shape=(96, 96, 3))\n",
    "\n",
    "# Output for anchor, positive and negative embedding vectors\n",
    "# The nn4_small model instance is shared (Siamese network)\n",
    "emb_a = nn4_small2(in_a)\n",
    "emb_p = nn4_small2(in_p)\n",
    "emb_n = nn4_small2(in_n)\n",
    "\n",
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        a, p, n = inputs\n",
    "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "\n",
    "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "triplet_loss_layer = TripletLossLayer(alpha=0.2, name='triplet_loss_layer')([emb_a, emb_p, emb_n])\n",
    "\n",
    "# Model that can be trained with anchor, positive negative images\n",
    "nn4_small2_train = Model([in_a, in_p, in_n], triplet_loss_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623583,
     "status": "ok",
     "timestamp": 1607029730293,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "PYOBUYxoR8VX",
    "outputId": "6ebe50b2-a78c-48f0-83b9-bd45ed1b3265"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py:819: UserWarning: Output triplet_loss_layer missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to triplet_loss_layer.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 175s 2s/step - loss: 0.8131\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 82s 824ms/step - loss: 0.7994\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 85s 849ms/step - loss: 0.8012\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 0.8002\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 0.8001\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 81s 807ms/step - loss: 0.8001\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 0.8006\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.8000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 71s 709ms/step - loss: 0.8001\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 74s 744ms/step - loss: 0.8001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16f763ed5c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import triplet_generator\n",
    "\n",
    "# triplet_generator() creates a generator that continuously returns \n",
    "# ([a_batch, p_batch, n_batch], None) tuples where a_batch, p_batch \n",
    "# and n_batch are batches of anchor, positive and negative RGB images \n",
    "# each having a shape of (batch_size, 96, 96, 3).\n",
    "generator = triplet_generator() \n",
    "\n",
    "nn4_small2_train.compile(loss=None, optimizer='adam')\n",
    "nn4_small2_train.fit_generator(generator, epochs=10, steps_per_epoch=100)\n",
    "\n",
    "# Please note that the current implementation of the generator only generates \n",
    "# random image data. The main goal of this code snippet is to demonstrate \n",
    "# the general setup for model training. In the following, we will anyway \n",
    "# use a pre-trained model so we don't need a generator here that operates \n",
    "# on real training data. I'll maybe provide a fully functional generator\n",
    "# later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2399,
     "status": "ok",
     "timestamp": 1607030022776,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "TQvlp-Z0TlWk"
   },
   "outputs": [],
   "source": [
    "nn4_small2_pretrained = create_model()\n",
    "nn4_small2_pretrained.load_weights('weights/nn4.small2.v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1607030025489,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "V5qwXxxVTqjD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "class IdentityMetadata():\n",
    "    def __init__(self, base, name, file):\n",
    "        # dataset base directory\n",
    "        self.base = base\n",
    "        # identity name\n",
    "        self.name = name\n",
    "        # image file name\n",
    "        self.file = file\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.image_path()\n",
    "\n",
    "    def image_path(self):\n",
    "        return os.path.join(self.base, self.name, self.file) \n",
    "    \n",
    "def load_metadata(path):\n",
    "    metadata = []\n",
    "    for i in sorted(os.listdir(path)):\n",
    "        for f in sorted(os.listdir(os.path.join(path, i))):\n",
    "            # Check file extension. Allow only jpg/jpeg' files.\n",
    "            ext = os.path.splitext(f)[1]\n",
    "            if ext == '.jpg' or ext == '.jpeg':\n",
    "                metadata.append(IdentityMetadata(path, i, f))\n",
    "    return np.array(metadata)\n",
    "\n",
    "metadata = load_metadata('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 7850,
     "status": "ok",
     "timestamp": 1607030034878,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "U1_vsZ8rT2mB",
    "outputId": "ecf589b7-7a8e-4bff-a1c0-7aac9897b977"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f81496378d35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0malign\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAlignDlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\DELL\\PythonProjects\\FaceRecognition\\align.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from align import AlignDlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    # OpenCV loads images with color channels\n",
    "    # in BGR order. So we need to reverse them\n",
    "    return img[...,::-1]\n",
    "\n",
    "# Initialize the OpenFace face alignment utility\n",
    "alignment = AlignDlib('models/landmarks.dat')\n",
    "\n",
    "# Load an image of Arpan\n",
    "jc_orig = load_image(metadata[10].image_path())\n",
    "\n",
    "# Detect face and return bounding box\n",
    "bb = alignment.getLargestFaceBoundingBox(jc_orig)\n",
    "\n",
    "# Transform image using specified face landmark indices and crop image to 96x96\n",
    "jc_aligned = alignment.align(96, jc_orig, bb, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "\n",
    "# Show original image\n",
    "plt.subplot(131)\n",
    "plt.imshow(jc_orig)\n",
    "\n",
    "# Show original image with bounding box\n",
    "plt.subplot(132)\n",
    "plt.imshow(jc_orig)\n",
    "plt.gca().add_patch(patches.Rectangle((bb.left(), bb.top()), bb.width(), bb.height(), fill=False, color='red'))\n",
    "\n",
    "# Show aligned image\n",
    "plt.subplot(133)\n",
    "plt.imshow(jc_aligned);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1106,
     "status": "ok",
     "timestamp": 1607031093606,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "1VEQ73rpVezx"
   },
   "outputs": [],
   "source": [
    "def align_image(img):\n",
    "    return alignment.align(96, img, alignment.getLargestFaceBoundingBox(img), landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 97750,
     "status": "ok",
     "timestamp": 1607030145930,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "1oNHIfu_ViNP"
   },
   "outputs": [],
   "source": [
    "embedded = np.zeros((metadata.shape[0], 128))\n",
    "for i, m in enumerate(metadata):\n",
    "    img = load_image(m.image_path())\n",
    "    img = align_image(img)\n",
    "    # scale RGB values to interval [0,1]\n",
    "    img = (img / 255.).astype(np.float32)\n",
    "    # obtain embedding vector for image\n",
    "    embedded[i] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 5850,
     "status": "ok",
     "timestamp": 1607031101497,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "oHBi1lNoVx59",
    "outputId": "5bddce87-a63f-4c85-cfe0-88922b21ce18"
   },
   "outputs": [],
   "source": [
    "def distance(emb1, emb2):\n",
    "    return np.sum(np.square(emb1 - emb2))\n",
    "\n",
    "def show_pair(idx1, idx2):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.suptitle(f'Distance = {distance(embedded[idx1], embedded[idx2]):.2f}')\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(load_image(metadata[idx1].image_path()))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(load_image(metadata[idx2].image_path()));    \n",
    "\n",
    "show_pair(10, 11)\n",
    "show_pair(10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1607031112210,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "xygFB5XOWw2i",
    "outputId": "dda83f3c-4170-4bbc-a19d-371e6555c039"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "identical = [] # 1 if same identity, 0 otherwise\n",
    "\n",
    "num = len(metadata)\n",
    "\n",
    "for i in range(num - 1):\n",
    "    for j in range(i + 1, num):\n",
    "        distances.append(distance(embedded[i], embedded[j]))\n",
    "        identical.append(1 if metadata[i].name == metadata[j].name else 0)\n",
    "        \n",
    "distances = np.array(distances)\n",
    "identical = np.array(identical)\n",
    "\n",
    "thresholds = np.arange(0.3, 1.0, 0.01)\n",
    "\n",
    "f1_scores = [f1_score(identical, distances < t) for t in thresholds]\n",
    "acc_scores = [accuracy_score(identical, distances < t) for t in thresholds]\n",
    "\n",
    "opt_idx = np.argmax(f1_scores)\n",
    "# Threshold at maximal F1 score\n",
    "opt_tau = thresholds[opt_idx]\n",
    "# Accuracy at maximal F1 score\n",
    "opt_acc = accuracy_score(identical, distances < opt_tau)\n",
    "\n",
    "# Plot F1 score and accuracy as function of distance threshold\n",
    "plt.plot(thresholds, f1_scores, label='F1 score');\n",
    "plt.plot(thresholds, acc_scores, label='Accuracy');\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title(f'Accuracy at threshold {opt_tau:.2f} = {opt_acc:.3f}');\n",
    "plt.xlabel('Distance threshold')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 1236,
     "status": "ok",
     "timestamp": 1607031138050,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "I2sYVeQQW6Gd",
    "outputId": "0bd3b499-59cc-4e65-9493-73d60c67c14d"
   },
   "outputs": [],
   "source": [
    "dist_pos = distances[identical == 1]\n",
    "dist_neg = distances[identical == 0]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(dist_pos)\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title('Distances (pos. pairs)')\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(dist_neg)\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title('Distances (neg. pairs)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1151,
     "status": "ok",
     "timestamp": 1607031153509,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "AJiF-N0LYzTt",
    "outputId": "ead87174-575c-4371-fc5d-6da640ba6787"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "targets = np.array([m.name for m in metadata])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(targets)\n",
    "\n",
    "# Numerical encoding of identities\n",
    "y = encoder.transform(targets)\n",
    "\n",
    "train_idx = np.arange(metadata.shape[0]) % 2 != 0\n",
    "test_idx = np.arange(metadata.shape[0]) % 2 == 0\n",
    "\n",
    "# 50 train examples of 10 identities (5 examples each)\n",
    "X_train = embedded[train_idx]\n",
    "# 50 test examples of 10 identities (5 examples each)\n",
    "X_test = embedded[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svc = LinearSVC()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "acc_knn = accuracy_score(y_test, knn.predict(X_test))\n",
    "acc_svc = accuracy_score(y_test, svc.predict(X_test))\n",
    "\n",
    "print(f'KNN accuracy = {acc_knn}, SVM accuracy = {acc_svc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 2098,
     "status": "ok",
     "timestamp": 1607031173703,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "yM7AGwckZFIy",
    "outputId": "118bbd17-7a7f-4fe9-8bd8-e9de3022d82c"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress LabelEncoder warning\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "example_idx = 6\n",
    "\n",
    "example_image = load_image(metadata[test_idx][example_idx].image_path())\n",
    "example_prediction = svc.predict([embedded[test_idx][example_idx]])\n",
    "example_identity = encoder.inverse_transform(example_prediction)[0]\n",
    "\n",
    "plt.imshow(example_image)\n",
    "plt.title(f'Recognized as {example_identity}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 1741,
     "status": "ok",
     "timestamp": 1607031178017,
     "user": {
      "displayName": "NERD-i PROJECT",
      "photoUrl": "",
      "userId": "11442613862398789611"
     },
     "user_tz": -330
    },
    "id": "Nii-I4WJZVi4",
    "outputId": "d7a707d6-19ce-4764-8c41-bad329e7aff0"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2).fit_transform(embedded)\n",
    "\n",
    "for i, t in enumerate(set(targets)):\n",
    "    idx = targets == t\n",
    "    plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=t)   \n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1));"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNS/ELE/H4wRkWCRs1dl/sd",
   "collapsed_sections": [],
   "name": "ImageRecognitionNew.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
